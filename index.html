<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Privacy Preserving Machine Learning (NeurIPS 2018 Workshop)</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <link href="css/style.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <span class="light">PPML'18</span>
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about">Scope</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">CFP &amp; Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#speakers">Invited Speakers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#schedule">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#grants">Travel Grants</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organizers">Organizers</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Privacy Preserving Machine Learning</h1>
                        <p class="intro-text">NeurIPS 2018 Workshop
                            <br />Montréal, December 8
                        </p>
                        <p class="location-text">
                            Palais des Congrès de Montréal
                            <br /> Room: 512CDGH
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Scope</h2>
                <p>This one day workshop focuses on privacy preserving techniques for training, inference, and disclosure in large scale data analysis, both in the distributed and centralized settings. We have observed increasing interest of the ML community in leveraging cryptographic techniques such as Multi-Party Computation (MPC) and Homomorphic Encryption (HE) for privacy preserving training and inference, as well as Differential Privacy (DP) for disclosure. Simultaneously, the systems security and cryptography community has proposed various secure frameworks for ML. We encourage both theory and application-oriented submissions exploring a range of approaches, including:</p>
                <ul class="list-group">
                    <li class="list-group-item speaker">secure multi-party computation techniques for ML</li>
                    <li class="list-group-item speaker">homomorphic encryption techniques for ML</li>
                    <li class="list-group-item speaker">hardware-based approaches to privacy preserving ML</li>
                    <li class="list-group-item speaker">centralized and decentralized protocols for learning on encrypted data</li>
                    <li class="list-group-item speaker">differential privacy: theory, applications, and implementations</li>
                    <li class="list-group-item speaker">statistical notions of privacy including relaxations of differential privacy</li>
                    <li class="list-group-item speaker">empirical and theoretical comparisons between different notions of privacy</li>
                    <li class="list-group-item speaker">trade-offs between privacy and utility</li>
                </ul>
                <p>We think it will be very valuable to have a forum to unify different perspectives and start a discussion about the relative merits of each approach. The workshop will also serve as a venue for networking people from different communities interested in this problem, and hopefully foster fruitful long-term collaboration.</p>
            </div>
        </div>
    </section>

    <!-- CFP & Dates Section -->
        <section id="dates" class="container content-section text-center">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Call For Papers &amp; Important Dates</h2>
                    <a href="cfp-ppml18.txt" class="btn btn-default btn-lg">Download Full CFP</a>
                    <br/>
                    <br/>
                    <br/>
                    <p><b>Submission deadline</b>: <s>October 8</s> October 16, 2018 (11:59pm AoE)
                        <br/><b>Notification of acceptance</b>: November 1, 2018
                        <!-- <br/><b>NIPS early <a href="https://nips.cc/Register/view-registration">registration</a> deadline</b>: October 24, 2018 -->
                        <br/><b>Workshop</b>: December 8, 2018</p>
                    <h3>Submission Instructions</h3>
                    <p>
                        Submissions in the form of extended abstracts must be <b>at most 4 pages long</b> (not including references and an unlimited number of pages for supplemental material, which reviewers are not required to take into account) and <b>adhere to the <a href="https://nips.cc/Conferences/2018/PaperInformation/StyleFiles">NeurIPS format</a></b>. We do accept submissions of work recently published or currently under review. Submissions should be anonymized. The workshop will not have formal proceedings, but authors of accepted abstracts can choose to have a link to arxiv or a pdf published on the workshop webpage.
                    </p>
                    <p>
                        If the new notification date causes issues with a potential visa application that depends specifically on the acceptance at this workshop, please contact us directly at <a href="mailto:ppml18@easychair.org?Subject=Regarding%20visa%20application" target="_top">ppml18@easychair.org</a>.
                    </p>
                    <p style="color: #d07200;">
                        We can offer the opportunity to purchase a NeurIPS registration to <b>one</b> author of each accepted paper.
                    </p>
                    <p>
                        From the <b><a href="https://nips.cc/Conferences/2018/AcceptedWorkshopFAQ">Workshop FAQ</a></b>:
                        <i>the reserve tickets guarantee attendance to the workshops, and depending on availability, also to the main conference and tutorials. We expect most of the reserve tickets to allow registration for tutorials, conference and workshops, but again, only the workshops part is for certain.</i>
                    </p>
                </div>
            </div>
        </section>

    <!-- Speakers Section -->
    <section id="speakers" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Invited Speakers</h2>
                <ul class="list-group">
                    <li class="list-group-item speaker"><a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a> (University of California, San Diego )</li>
                    <li class="list-group-item speaker"><a href="https://people.csail.mit.edu/shafi/">Shafi Goldwasser</a> (MIT & Weizmann Institute of Science)</li>
                    <li class="list-group-item speaker"><a href="http://www.iangoodfellow.com/">Ian Goodfellow</a> (Google Brain)</li>
                    <li class="list-group-item speaker"><a href="http://www.cse.psu.edu/~ads22/">Adam Smith</a> (Boston University)</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Schedule Section -->
    <section id="schedule" class="container content-section text-center">
        <div class="row">
            <div class="col-sm-8 col-sm-offset-2">
                <h2>Schedule</h2>
                <table class="table schedule">
                    <tbody>
                    <tr>
                        <td class="time">8:30</td>
                        <td class="slot">Welcome and Introduction</td>
                    </tr>

                    <tr>
                        <td class="time">8:50</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs2" data-toggle="collapse" class="accordion-toggle">
                        Ian Goodfellow
                        &mdash;
                        TBA
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs2">
                            Coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">9:40</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs3" data-toggle="collapse" class="accordion-toggle">
                        Shafi Goldwasser
                        &mdash;
                        Machine Learning and Cryptography: Challenges and Opportunities
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs3">
                            At the mid eighties researchers in computational learning theory pointed the way to  examples of hard learning tasks such as learning parity with noise (LPN) and learning with errors (LWE) which have been extremely useful for building sophisticated cryptographic primitives such as homomorphic encryption which are unbreakable if LPN and LWE are hard to learn.
                            <br/>
                            Today, with the rise of machine learning algorithms that use large amounts of data to come up with procedures which have the potential to replace human decision processes, cryptography, in turn,  stands to provide machine learning, tools for keeping data private during both training and inference phases of ML and to provide methods to verify adherence of models with data. These promise to be important steps in ensuring the safe transition of  power from human to algorithmic decision making.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">10:30</td>
                        <td class="break">Coffee break</td>
                    </tr>

                    <tr>
                        <td class="time">11:00</td>
                        <td class="slot talk"><a href="#tabs4" data-toggle="collapse" class="accordion-toggle">
                        Privacy Amplification by Iteration
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs4">
                            Many commonly used learning algorithms work by iteratively updating an intermediate solution using one or a few data points in each iteration. Analysis of differential privacy for such algorithms often involves ensuring privacy of each step and then reasoning about the cumulative privacy cost of the algorithm. This is enabled by composition theorems for differential privacy that allow releasing of all the intermediate results. In this work, we demonstrate that for contractive iterations, not releasing the intermediate results strongly amplifies the privacy guarantees.
                            <br/>
                            We describe several applications of this new analysis technique to solving convex optimization problems via noisy stochastic gradient descent. For example, we demonstrate that a relatively small number of non-private data points from the same distribution can be used to close the gap between private and non-private convex optimization. In addition, we demonstrate that we can achieve guarantees similar to those obtainable using the privacy-amplification-by-sampling technique in several natural settings where that technique cannot be applied.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">11:15</td>
                        <td class="slot talk"><a href="#tabs5" data-toggle="collapse" class="accordion-toggle">
                        Subsampled Renyi Differential Privacy and Analytical Moments Accountant
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs5">
                            We study the problem of subsampling in differential privacy (DP), a question that is the centerpiece behind many successful differentially private machine learning algorithms. Specifically, we provide a tight upper bound on the Renyi Differential Privacy (RDP) parameters for algorithms that: (1) subsample the dataset, and then (2) applies a randomized mechanism M to the subsample, in terms of the RDP parameters of M and the subsampling probability parameter. Our results generalize the moments accounting technique, developed by Abadi et al. [CCS'16] for the Gaussian mechanism, to any subsampled RDP mechanism.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">11:30</td>
                        <td class="slot talk"><a href="#tabs6" data-toggle="collapse" class="accordion-toggle">
                        The Power of The Hybrid Model for Mean Estimation
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs6">
                            In this work we explore the power of the hybrid model of differential privacy (DP) proposed in~\cite{blender}, where some users desire the guarantees of the local model of DP and others are content with receiving the trusted curator model guarantees. In particular, we study the accuracy of mean estimation algorithms for arbitrary distributions in bounded support. We show that a hybrid mechanism which combines the sample mean estimates obtained from the two groups in an optimally weighted convex combination performs a constant factor better for a wide range of sample sizes than natural benchmarks. We analyze how this improvement factor is parameterized by the problem setting and how it varies with sample size.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">11:45</td>
                        <td class="slot talk"><a href="#tabs7" data-toggle="collapse" class="accordion-toggle">
                        DP-MAC: The Differentially Private Method of Auxiliary Coordinates for Deep Learning
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs7">
                            Developing a differentially private deep learning algorithm is challenging, due to the difficulty in analyzing the sensitivity of objective functions that are typically used to train deep neural networks. Many existing methods resort to the stochastic gradient descent algorithm and apply a pre-defined sensitivity to the gradients for privatizing weights. However, their slow convergence typically yields a high cumulative privacy loss. Here, we take a different route by employing the method of auxiliary coordinates, which allows us to independently update the weights per layer by optimizing a per-layer objective function. This objective function can be well approximated by a low-order Taylor's expansion, in which sensitivity analysis becomes tractable. We perturb the coefficients of the expansion for privacy, which we optimize using more advanced optimization routines than SGD for faster convergence. We empirically show that our algorithm provides a decent trained model quality under a modest privacy budget.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">12:00</td>
                        <td class="break">Lunch break</td>
                    </tr>

                    <tr>
                        <td class="time">13:30</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs8" data-toggle="collapse" class="accordion-toggle">
                        Kamalika Chaudhuri
                        &mdash;
                        Challenges in the Privacy-Preserving Analysis of Structured Data
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs8">
                            Much data analysis today is done on sensitive data, and particular privacy challenges arise when this data is sensitive and structured. In this talk I will describe two such challenges in the privacy-preserving analysis of complex, structured data that we have been working on in my group.
                            <br/>
                            The first is continual release of graph statistics in an online manner from an expanding graph, which is motivated by a problem in HIV epidemiology. Even though node differentially private release of graph statistics is highly challenging, here we will describe how we can get a differentially private solution for this problem that performs better than the natural sequential composition baseline.
                            <br/>
                            Next, I will talk about analysis of sensitive structured, correlated data, while still preserving the privacy of events in the data. Differential privacy does not adequately address privacy issues in this kind of data, and hence will look at a form of inferential privacy, called Pufferfish, that is more appropriate. We will provide mechanisms, establish their composition properties, and finally evaluate them on real data on physical activity measurements across time.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">14:20</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs9" data-toggle="collapse" class="accordion-toggle">
                        Adam Smith
                        &mdash;
                        TBA
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs9">
                            Coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">15:10</td>
                        <td class="break">Coffee break</td>
                    </tr>

                    <tr>
                        <td class="time">15:30</td>
                        <td class="slot talk"><a href="#tabs10" data-toggle="collapse" class="accordion-toggle">
                        Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs10">
                            Sensitive statistics are often collected across sets of users, with repeated collection of reports done over time. For example, trends in users' private preferences or software usage may be monitored via such reports. We study the collection of such statistics in the local differential privacy (LDP) model, when each user's value may change only a small number of times. We describe an algorithm whose privacy cost is polylogarithmic in the number of times the statistic is collected.
                            <br/>
                            More fundamentally---by building on anonymity of the users' reports---we also demonstrate how the privacy cost of our LDP algorithm can actually be much lower when viewed in the central model of differential privacy. We show, via a new and general technique, that any permutation-invariant algorithm satisfying $\varepsilon$-local differential privacy will satisfy $(O(\varepsilon \sqrt{\log \frac 1 \delta} / \sqrt{n}), \delta)$-central differential privacy. In the process, we clarify how the high noise and $\sqrt{n}$ overhead of LDP protocols is a consequence of them being significantly more private in the central model. As a final, practical corollary, our results also imply that industrial deployments of LDP mechanism may have much lower privacy cost than their advertised $\varepsilon$ would indicate---at least if reports are anonymized.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">15:45</td>
                        <td class="slot talk"><a href="#tabs11" data-toggle="collapse" class="accordion-toggle">
                        Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs11">
                            As Machine Learning (ML) gets applied to security-critical or sensitive domains, there is a growing need for integrity and privacy for outsourced ML computations. A pragmatic solution comes from Trusted Execution Environments (TEEs), which use hardware and software protections to isolate sensitive computations from the untrusted software stack. However, these isolation guarantees come at a price in performance, compared to untrusted alternatives. This paper initiates the study of high performance execution of Deep Neural Networks (DNNs) in TEEs by efficiently partitioning DNN computations between trusted and untrusted devices. Building upon an efficient outsourcing scheme for matrix multiplication, we propose Slalom, a framework that securely delegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX or Sanctum) to a faster, yet untrusted, co-located processor. We evaluate Slalom by executing DNNs in an Intel SGX enclave, which selectively delegates work to an untrusted GPU. For two canonical DNNs, VGG16 and MobileNet, we obtain 20× and 6× increases in throughput for verifiable inference, and 11× and 4× for verifiable and private inference.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">16:00</td>
                        <td class="slot talk"><a href="#tabs12" data-toggle="collapse" class="accordion-toggle">
                        Secure Two Party Distribution Testing
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs12">
                            We study the problem of discrete distribution testing in the two-party setting. For example, in the standard closeness testing problem, Alice and Bob each have t samples from, respectively, distributions a and b over [n], and they need to test whether a=b or a,b are ε-far (in the ℓ1 distance) for some fixed ε>0. This is in contrast to the well-studied one-party case, where the tester has unrestricted access to samples of both distributions, for which optimal bounds are known for a number of variations. Despite being a natural constraint in applications, the two-party setting has evaded attention so far.
                            <br/>
                            We address two fundamental aspects of the two-party setting: 1) what is the communication complexity, and 2) can it be accomplished securely, without Alice and Bob learning extra information about each other's input. Besides closeness testing, we also study the independence testing problem, where Alice and Bob have t samples from distributions a and b respectively, which may be correlated; the question is whether a,b are independent of ε-far from being independent.
                            <br/><br/>
                            Our contribution is three-fold:
                            <br/>
                            ∙ Communication: we show how to gain communication efficiency as we have more samples, beyond the information-theoretic bound on t. Furthermore, the gain is polynomially better than what one may obtain by adapting one-party algorithms.
                            <br/>
                            For the closeness testing, our protocol has communication s=Θ_ε(n^2/t^2) as long as t is at least the information-theoretic minimum number of samples. For the independence testing over domain [n]×[m], where n≥m, we obtain s=O_ε(n^2m/t^2+nm/t+m^1/2).
                            <br/>
                            ∙ Security: we define the concept of secure distribution testing and argue that it must leak at least some minimal information when the promise is not satisfied. We then provide secure versions of the above protocols with an overhead that is only polynomial in the security parameter.
                            <br/>
                            ∙ Lower bounds: we prove tightness of our trade-off for the closeness testing, as well as that the independence testing requires tight Ω(m^1/2) communication for unbounded number of samples. These lower bounds are of independent interest as, to the best of our knowledge, these are the first 2-party communication lower bounds for testing problems, where the inputs represent a set of i.i.d. samples.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">16:15</td>
                        <td class="slot talk"><a href="#tabs13" data-toggle="collapse" class="accordion-toggle">
                        Private Machine Learning in TensorFlow using Secure Computation
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs13">
                            We present a framework for experimenting with secure multi-party computation directly in TensorFlow. By doing so we benefit from several properties valuable to both researchers and practitioners, including tight integration with ordinary machine learning processes, existing optimizations for distributed computation in TensorFlow, high-level abstractions for expressing complex algorithms and protocols, and an expanded set of familiar tooling. We give an open source implementation of a state-of-the-art protocol and report on concrete benchmarks using typical models from private machine learning.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">16:30</td>
                        <td class="slot talk"><a href="#tabs14" data-toggle="collapse" class="accordion-toggle">
                        Spotlight talks
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs14">
                            Order coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">17:15</td>
                        <td class="slot">Poster session</td>
                    </tr>

                    <tr>
                        <td class="time">18:15</td>
                        <td class="slot">Wrap up</td>
                    </tr>

        		    </tbody>
        		</table>
            </div>
        </div>
    </section>

    <!-- Accepted Papers -->
    <section id="papers" class="container content-section text-center">
        <div class="row">
        <div class="col-lg-8 col-lg-offset-2">
            <h2>Accepted Papers</h2>
                <h4 style="color: #d07200;">
                Links to pdfs as well as abstracts will be added soon.
                </h4>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Hsin-Pai Cheng, Patrick Yu, Haojing Hu, Hai Li and Yiran Chen
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs1" class="paper-title">
                        LEASGD: an Efficient and Privacy-Preserving Decentralized Algorithm for Distributed Learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs1" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Garrett Bernstein and Daniel Sheldon
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs2" class="paper-title">
                            Differentially Private Bayesian Inference for Exponential Families
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs2" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Cynthia Dwork and Vitaly Feldman
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs3" class="paper-title">
                            Privacy-preserving Prediction
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs3" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Bolin Ding, Janardhan Kulkarni and Sergey Yekhanin
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs4" class="paper-title">
                            A Distributed Algorithm For Differentially Private Heavy Hitters
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs4" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Yunhui Long, Tanmay Gangwani, Haris Mughees and Carl Gunter
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs5" class="paper-title">
                            Distributed and Secure Machine Learning using Self-tallying Multi-party Aggregation
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs5" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Di Wang, Adam Smith and Jinhui Xu
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs6" class="paper-title">
                            High Dimensional Sparse Linear Regression under Local Differential Privacy: Power and Limitations
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs6" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Joshua Allen, Bolin Ding, Janardhan Kulkarni, Harsha Nori, Olga Ohrimenko and Sergey Yekhanin
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs7" class="paper-title">
                            An Algorithmic Framework For Differentially Private Data Analysis on Trusted Processors
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs7" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Antoine Boutet, Théo Jourdan and Carole Frindel
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs8" class="paper-title">
                            Toward privacy in IoT mobile devices for activity recognition
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs8" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter, Saeed Maleki, Madanlal Musuvathi and Todd Mytkowicz
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs9" class="paper-title">
                            CHET: Compiler and Runtime for Homomorphic Evaluation of Tensor Programs
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs9" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Martin Bertran, Natalia Martinez, Afroditi Papadaki, Qiang Qiu, Miguel Rodrigues and Guillermo Sapiro
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs10" class="paper-title">
                            Learning Representations for Utility and Privacy: An Information-Theoretic Based Approach
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs10" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Florian Tramer and Dan Boneh
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs11" class="paper-title">
                            Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs11" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Ashwin Machanavajjhala and Kamalika Chaudhuri
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs12" class="paper-title">
                            Capacity Bounded Differential Privacy
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs12" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Aurélien Bellet, Rachid Guerraoui and Hadrien Hendrikx
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs13" class="paper-title">
                            Who started this gossip? Differentially private rumor spreading
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs13" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Koen Lennart van der Veen, Ruben Seggers, Peter Bloem and Giorgio Patrini
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs14" class="paper-title">
                            Three Tools for Practical Differential Privacy
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs14" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Fabrice Benhamouda and Marc Joye
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs15" class="paper-title">
                            How to Profile Privacy-Conscious Users in Recommender Systems
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs15" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Hao Chen, Ilaria Chillotti, Oxana Poburinnaya, Ilya Razenshteyn and M. Sadegh Riazi
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs16" class="paper-title">
                            Scaling Up Secure Nearest Neighbor Search
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs16" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Vitaly Feldman, Ilya Mironov, Kunal Talwar and Abhradeep Thakurta
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs17" class="paper-title">
                            Privacy Amplification by Iteration <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs17" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Antti Koskela and Antti Honkela
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs18" class="paper-title">
                            Learning rate adaptation for differentially private stochastic gradient descent
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs18" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Yu-Xiang Wang, Borja Balle and Shiva Kasiviswanathan
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs19" class="paper-title">
                            Subsampled Renyi Differential Privacy and Analytical Moments Accountant <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs19" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert and Jonathan Passerat-Palmbach
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs20" class="paper-title">
                            A generic framework for privacy preserving deep learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs20" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Valerie Chen, Valerio Pastro and Mariana Raykova
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs21" class="paper-title">
                            Secure Computation for Machine Learning With SPDZ
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs21" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Kareem Amin, Travis Dick, Alex Kulesza, Andres Medina and Sergei Vassilvitskii
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs22" class="paper-title">
                            Private Covariance Estimation via Iterative Eigenvector Sampling
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs22" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Alexandr Andoni, Tal Malkin and Negev Shekel Nosatzki
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs23" class="paper-title">
                            Secure Two Party Distribution Testing <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs23" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Phillipp Schoppmann, Adria Gascon, Mariana Raykova and Benny Pinkas
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs24" class="paper-title">
                            Make Some ROOM for the Zeros: Data Sparsity in Secure Distributed Machine Learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs24" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Judy Hoffman, Mehryar Mohri and Ningshan Zhang
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs25" class="paper-title">
                            Algorithms and Theory for Multiple-Source Adaptation
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs25" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Kareem Amin, Alex Kulesza, Andres Munoz Medina and Sergei Vassilvitskii
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs26" class="paper-title">
                            Bias Variance Trade-off in Differential Privacy
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs26" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Sesh Kumar and Marc Deisenroth
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs27" class="paper-title">
                            Differentially Private Empirical Risk Minimization with Sparsity-Inducing Norms
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs27" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Morten Dahl, Jason Mancuso, Yann Dupis, Ben DeCoste, Morgan Giraud, Ian Livingstone, Justin Patriquin and Gavin Uhma
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs28" class="paper-title">
                            Private Machine Learning in TensorFlow using Secure Computation <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs28" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Nicolas Loizou, Peter Richtarik, Filip Hanzely, Jakub Konecny and Dmitry Grishchenko
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs29" class="paper-title">
                            A Privacy Preserving Randomized Gossip Algorithm via Controlled Noise Insertion
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs29" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Yatharth Dubey and Aleksandra Korolova
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs30" class="paper-title">
                            The Power of The Hybrid Model for Mean Estimation <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs30" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar and Abhradeep Thakurta
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs31" class="paper-title">
                            Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs31" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Vasyl Pihur, Aleksandra Korolova, Frederick Liu, Subhash Sankuratripati, Moti Yung, Dachuan Huang and Ruogu Zeng
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs32" class="paper-title">
                            Differentially Private "Draw and Discard" Machine Learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs32" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Brendan McMahan and Galen Andrew
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs33" class="paper-title">
                            A General Approach to Adding Differential Privacy to Iterative Training Procedures
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs33" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Alexandra Schofield, Aaron Schein, Zhiwei Steven Wu and Hanna Wallach
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs34" class="paper-title">
                            A Variational Inference Approach for Locally Private Inference of Poisson Factorization Models
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs34" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Siddharth Garg, Zahra Ghodsi, Carmit Hazay, Yuval Ishai, Antonio Mercedone and Muthuramakrishnan Venkitasubramaniam
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs35" class="paper-title">
                            Oursourcing Private Machine Learning via Lightweight Secure Arithmetic Computation
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs35" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Frederik Harder, Jonas Köhler, Max Welling and Mijung Park
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs36" class="paper-title">
                            DP-MAC: The Differentially Private Method of Auxiliary Coordinates for Deep Learning <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs36" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            Da Yu, Huishuai Zhang and Wei Chen
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs37" class="paper-title">
                            Improving the Gradient Perturbation Approach for Differentially Private Optimization
                        </a> &nbsp;&nbsp;
                        <!-- <a href="papers/paper.pdf" class="link-paper">[PDF]</a> -->
                    </div>
                    <div id="abs37" class="panel-footer panel-paper-footer collapse">
                    Coming soon
                    </div>
                </div>

        </div>
        </div>
    </section>

    <!-- Call for travel grants -->
        <section id="grants" class="container content-section text-center">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Travel Grants</h2>
                    <p>
                    Thanks to our generous sponsors, we are able to provide a limited number of travel grants of up to $800 to help partially cover the expenses of authors of accepted papers who have not received other travel support from NeurIPS this year.
                    To apply, please send an email to <a href="mailto:ppml18@easychair.org?Subject=PPML18%20Travel%20Grant%20Application">ppml18@easychair.org</a> with the subject “PPML18 Travel Grant Application” including your resume and a half-page statement of purpose mentioning the title and the authors of your accepted paper and a summary of anticipated travel expenses. If you are an undergraduate or graduate student, we ask for a half-page recommendation letter supporting your application to be sent to us by the deadline. The deadline for applications is <b>November 11, 2018 (11:59pm AoE)</b>. The notifications will be sent by <b>November 16</b>. Please feel free to send us an email if you have any questions.
                </div>
            </div>
        </section>

    <!-- Organizers Section -->
    <section id="organizers" class="content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Organization</h2>
                <br />
                <h3>Workshop organizers</h3>
                <ul class="list-group">
                    <li class="list-group-item organizer">Aurélien Bellet (Inria)</li>
                    <li class="list-group-item organizer">Adrià Gascón (Alan Turing Institute & Warwick)</li>
                    <li class="list-group-item organizer">Niki Kilbertus (MPI for Intelligent Systems & Cambridge)</li>
                    <li class="list-group-item organizer">Olya Ohrimenko (Microsoft Research)</li>
                    <li class="list-group-item organizer">Mariana Raykova (Yale)</li>
                    <li class="list-group-item organizer">Adrian Weller (Alan Turing Institute & Cambridge)</li>
                </ul>
                <br />
                <h3>Program Committee</h3>
                <ul class="list-group">
                    <li class="list-group-item organizer">Pauline Anthonysamy (Google)</li>
                    <li class="list-group-item organizer">Borja de Balle Pigem (Amazon)</li>
                    <li class="list-group-item organizer">James Bell (University of Cambridge)</li>
                    <li class="list-group-item organizer">Battista Biggio (University of Cagliari)</li>
                    <li class="list-group-item organizer">Keith Bonawitz (Google)</li>
                    <li class="list-group-item organizer">Graham Cormode (University of Warwick)</li>
                    <li class="list-group-item organizer">Morten Dahl (Dropout Labs)</li>
                    <li class="list-group-item organizer">Emiliano de Cristofaro (University College London)</li>
                    <li class="list-group-item organizer">Christos Dimitrakakis</li>
                    <li class="list-group-item organizer">David Evans (University of Virginia)</li>
                    <li class="list-group-item organizer">Joseph Geumlek (UCSD)</li>
                    <li class="list-group-item organizer">Irene Giacomelli (Wisconsin University)</li>
                    <li class="list-group-item organizer">Stephen Hardy (Data61)</li>
                    <li class="list-group-item organizer">Stratis Ioannidis (Northeastern University)</li>
                    <li class="list-group-item organizer">Peter Kairouz (Stanford)</li>
                    <li class="list-group-item organizer">Nadin Kokciyan (King's College London)</li>
                    <li class="list-group-item organizer">Aleksandra Korolova (USC)</li>
                    <li class="list-group-item organizer">Kim Laine (Microsoft Research)</li>
                    <li class="list-group-item organizer">Ashwin Machanavajjhala (Duke University)</li>
                    <li class="list-group-item organizer">Payman Mohassel (Visa Research)</li>
                    <li class="list-group-item organizer">Catuscia Palamidessi (École Polytechnique & INRIA)</li>
                    <li class="list-group-item organizer">Mijung Park (Max Planck Institute for Intelligent Systems)</li>
                    <li class="list-group-item organizer">Giorgio Patrini (University of Amsterdam)</li>
                    <li class="list-group-item organizer">Benjamin Rubinstein (University of Melbourne)</li>
                    <li class="list-group-item organizer">Anand Sarwate (Rutgers University)</li>
                    <li class="list-group-item organizer">Phillipp Schoppmann (HU Berlin)</li>
                    <li class="list-group-item organizer">Nigel Smart (KU Leuven)</li>
                    <li class="list-group-item organizer">Carmela Troncoso (EPFL)</li>
                    <li class="list-group-item organizer">Yu-Xiang Wang (UCSB)</li>
                    <li class="list-group-item organizer">Pinar Yolum (Utrecht University)</li>
                    <li class="list-group-item organizer">Samee Zahur (Google)</li>
                </ul>
                <br />
                <h3>Sponsors</h3>
                <br />
                    <img style="margin:50px;"height="80" src="img/ati-white.png">
                    <img style="margin:50px;"height="80" src="img/amazon.png">
                    <img style="margin:50px;"height="80" src="img/google.png">
                    <img style="margin:50px;"height="80" src="img/microsoft.png">
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Contact us: <a href="mailto:ppml18@easychair.org">ppml18@easychair.org</a></p>
            <br/>
        </div>

    </footer>

    <!-- jQuery -->
    <script src="js/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/script.js"></script>

</body>

</html>
